{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e0f2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "%matplotlib inline \n",
    "import h5py\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pyloudnorm as pyln"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023a940",
   "metadata": {},
   "source": [
    "## Downmix the 5.1 audio to stereo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74d5ab9",
   "metadata": {},
   "source": [
    "### Split to mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f4e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/vio/Desktop/Surround.wav\"\n",
    "surround_sound = AudioSegment.from_file(path, format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac1471a",
   "metadata": {},
   "source": [
    "### Assign channels direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285309fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = surround_sound.split_to_mono()\n",
    "front_left = channels[0]\n",
    "front_right = channels[1]\n",
    "center = channels[2]\n",
    "lfe = channels[3]\n",
    "surround_left = channels[4]\n",
    "surround_right = channels[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223fbac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydub.audio_segment.AudioSegment"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(front_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0fdb6a",
   "metadata": {},
   "source": [
    "### Playback each channel to check direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94370398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, convert audioSegment to a NumPy array\n",
    "def segment_to_nparray(audio_segment):\n",
    "    # Pydub audio segments are in milliseconds -> have to convert them to samples:\n",
    "    # AudioSegment's .get_array_of_samples() returns the audio data as an array of samples.\n",
    "    samples = np.array(audio_segment.get_array_of_samples())\n",
    "    \n",
    "    if audio_segment.sample_width == 2:\n",
    "        samples = samples.astype(np.int24)\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36166d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the front left channel\n",
    "front_left_np = segment_to_nparray(channels[0])\n",
    "Audio(front_left_np, rate=channels[0].frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5fb35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the front right channel\n",
    "front_right_np = segment_to_nparray(channels[1])\n",
    "Audio(front_right_np, rate=channels[1].frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc99ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center\n",
    "# Notice: 2:05 has no music element\n",
    "center_np = segment_to_nparray(channels[2])\n",
    "Audio(center_np, rate=channels[2].frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce983d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the lfe\n",
    "# Found that it's mostly silent except for some sub effect like 3:45\n",
    "lfe_np = segment_to_nparray(channels[3])\n",
    "Audio(lfe_np, rate=channels[3].frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7371c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play surround_left\n",
    "# Notice: Less drums (e.g. at 2:25)\n",
    "surround_left_np = segment_to_nparray(channels[4])\n",
    "Audio(surround_left_np, rate=channels[4].frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0716933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play surround_right\n",
    "# Notice: Less drums\n",
    "surround_right_np = segment_to_nparray(channels[5])\n",
    "Audio(surround_right_np, rate=channels[5].frame_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d3eae2",
   "metadata": {},
   "source": [
    "### Create stereo mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1156aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='stereo_downmix.wav'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center_left = center.pan(-1)  # Full left\n",
    "center_right = center.pan(1)  # Full right\n",
    "\n",
    "# Overlay the left channels to create the left tracks; and so does the right.\n",
    "left = front_left.overlay(center_left).overlay(surround_left)\n",
    "right = front_right.overlay(center_right).overlay(surround_right)\n",
    "\n",
    "# Ensure the tracks are mono by converting them explicitly\n",
    "left = left.set_channels(1)\n",
    "right = right.set_channels(1)\n",
    "\n",
    "# create stereo mix\n",
    "stereo_mix = AudioSegment.from_mono_audiosegments(left, right)\n",
    "\n",
    "# Output and save\n",
    "stereo_mix.export(\"stereo_downmix.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6d1f1f",
   "metadata": {},
   "source": [
    "### Read HRIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ea9086b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRIR Data Shape: (8802, 2, 256)\n",
      "Sampling Rate: 48000.0 Hz\n",
      "Listener Position: [[0. 0. 0.]]\n",
      "Source Positions: [[  0.  -90.    1.2]\n",
      " [  0.  -81.    1.2]\n",
      " [  0.  -75.    1.2]\n",
      " ...\n",
      " [359.   60.    1.2]\n",
      " [359.   64.8   1.2]\n",
      " [359.   75.    1.2]]\n",
      "HRIR Data Shape (number of measurements, stereo, n_samples): (8802, 2, 256)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/Users/vio/Downloads/D2_HRIR_SOFA/D2_48K_24bit_256tap_FIR_SOFA.sofa', 'r') as f:\n",
    "    hrir_data = f['Data.IR'][:]  # Get HRIR/BRIR data\n",
    "    sampling_rate = f['Data.SamplingRate'][:]\n",
    "    listener_position = f['ListenerPosition'][:]\n",
    "    source_positions = f['SourcePosition'][:]\n",
    "    print(f\"HRIR Data Shape: {hrir_data.shape}\")\n",
    "    print(f\"Sampling Rate: {sampling_rate[0]} Hz\")\n",
    "    print(f\"Listener Position: {listener_position}\")\n",
    "    print(f\"Source Positions: {source_positions}\")\n",
    "    print(\"HRIR Data Shape (number of measurements, stereo, n_samples):\", hrir_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff79c43e",
   "metadata": {},
   "source": [
    "### Get the standard 5.1 speaker placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b678a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRIR for position [30, 0, 1.2]: index 760, shape (2, 256)\n",
      "HRIR for position [330, 0, 1.2]: index 8064, shape (2, 256)\n"
     ]
    }
   ],
   "source": [
    "# Front Left and Front Right Speakers\n",
    "# Azimuth: +30 degrees and -30 degrees relative to the center front (0 degrees)\n",
    "\n",
    "#Target [  +30.  0.    1.2] and [  -30.  0.    1.2]\n",
    "target_positions = [[30, 0, 1.2], [330, 0, 1.2]]\n",
    "\n",
    "# Iterate over target positions and find the indices and HRIR data\n",
    "for pos in target_positions:\n",
    "    # Find indices where source position matches the target position\n",
    "    indices = np.where((source_positions[:, 0] == pos[0]) &\n",
    "                        (source_positions[:, 1] == pos[1]) &\n",
    "                        (source_positions[:, 2] == pos[2]))[0]\n",
    "\n",
    "    if len(indices) > 0:\n",
    "        # Get the HRIR data for the found indices\n",
    "        for index in indices:\n",
    "            hrir_for_position = hrir_data[index]\n",
    "            print(f\"HRIR for position {pos}: index {index}, shape {hrir_for_position.shape}\")\n",
    "    else:\n",
    "        print(f\"No HRIR found for position {pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e5b0b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRIR for center position: index 12, shape (2, 256)\n"
     ]
    }
   ],
   "source": [
    "# Center\n",
    "# Target [  0.  0.    1.2]\n",
    "center_position = [0, 0, 1.2]\n",
    "indices = np.where((source_positions[:, 0] == center_position[0]) &\n",
    "                       (source_positions[:, 1] == center_position[1]) &\n",
    "                       (source_positions[:, 2] == center_position[2]))[0]\n",
    "\n",
    "if len(indices) > 0:\n",
    "    # Get the HRIR data for the found indices\n",
    "    for index in indices:\n",
    "        hrir_for_center = hrir_data[index]\n",
    "        print(f\"HRIR for center position: index {index}, shape {hrir_for_center.shape}\")\n",
    "else:\n",
    "    print(\"No HRIR found for center position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1848fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRIR for lfe position: index 369, shape (2, 256)\n"
     ]
    }
   ],
   "source": [
    "# LFE\n",
    "# Target [  15.  -15.    1.2]\n",
    "lfe_position = [15, -15, 1.2]\n",
    "indices = np.where((source_positions[:, 0] == lfe_position[0]) &\n",
    "                       (source_positions[:, 1] == lfe_position[1]) &\n",
    "                       (source_positions[:, 2] == lfe_position[2]))[0]\n",
    "\n",
    "if len(indices) > 0:\n",
    "    # Get the HRIR data for the found indices\n",
    "    for index in indices:\n",
    "        hrir_for_lfe = hrir_data[index]\n",
    "        print(f\"HRIR for lfe position: index {index}, shape {hrir_for_lfe.shape}\")\n",
    "else:\n",
    "    print(\"No HRIR found for center position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f9f6895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRIR for position [120, 15, 1.2]: index 2950, shape (2, 256)\n",
      "HRIR for position [240, 15, 1.2]: index 5876, shape (2, 256)\n"
     ]
    }
   ],
   "source": [
    "# SL and SR\n",
    "# Target [  +120.  15.    1.2] and [  -120.  15.    1.2]\n",
    "rear_positions = [[120, 15, 1.2], [240, 15, 1.2]]\n",
    "\n",
    "for pos in rear_positions:\n",
    "    # Find indices where source position matches the target position\n",
    "    indices = np.where((source_positions[:, 0] == pos[0]) &\n",
    "                         (source_positions[:, 1] == pos[1]) &\n",
    "                         (source_positions[:, 2] == pos[2]))[0]\n",
    "\n",
    "    if len(indices) > 0:\n",
    "         # Get the HRIR data for the found indices\n",
    "        for index in indices:\n",
    "            hrir_for_position = hrir_data[index]\n",
    "            print(f\"HRIR for position {pos}: index {index}, shape {hrir_for_position.shape}\")\n",
    "    else:\n",
    "        print(f\"No HRIR found for position {pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a68080",
   "metadata": {},
   "source": [
    "### Plot the positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0be44a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = {\n",
    "    (30, 0, 1.2): 'blue',    # Front right\n",
    "    (330, 0, 1.2): 'blue',   # Front left (330 degrees is equivalent to -30 degrees)\n",
    "    (0, 0, 1.2): 'blue',     # Center front\n",
    "    (15, -15, 1.2): 'blue',  # Slightly front-right and below\n",
    "    (120, 15, 1.2): 'blue',  # Surround left\n",
    "    (240, 15, 1.2): 'blue',  # Surround right\n",
    "    (0, 0, 0): 'red'         # Origin\n",
    "}\n",
    "\n",
    "# Convert each position to Cartesian coordinates for plotting\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "colors = []\n",
    "\n",
    "for (azimuth, elevation, distance), color in positions.items():\n",
    "    # Convert spherical to Cartesian coordinates\n",
    "    azimuth_rad = np.radians(azimuth)\n",
    "    elevation_rad = np.radians(elevation)\n",
    "    x_coord = distance * np.cos(elevation_rad) * np.cos(azimuth_rad)\n",
    "    y_coord = distance * np.cos(elevation_rad) * np.sin(azimuth_rad)\n",
    "    z_coord = distance * np.sin(elevation_rad)\n",
    "\n",
    "    # Append coordinates and color\n",
    "    x.append(x_coord)\n",
    "    y.append(y_coord)\n",
    "    z.append(z_coord)\n",
    "    colors.append(color)\n",
    "\n",
    "# Create a 3D scatter plot with Plotly\n",
    "scatter_plot = go.Scatter3d(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=colors,  # Use the color array here\n",
    "        opacity=0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "# Layout configuration\n",
    "layout = go.Layout(\n",
    "    title='Interactive 3D Plot of Specified Source Positions',\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='X (meters)', range=[-1.5, 1.5]),\n",
    "        yaxis=dict(title='Y (meters)', range=[-1.5, 1.5]),\n",
    "        zaxis=dict(title='Z (meters)', range=[-1.5, 1.5]),\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='Z',\n",
    "        aspectmode='cube'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a figure and plot it\n",
    "fig = go.Figure(data=[scatter_plot], layout=layout)\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef490f3",
   "metadata": {},
   "source": [
    "### Load HRIR and Convert to 44.1kHz (to match my audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da9d6974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 8064 - Left HRIR shape: (236,), Right HRIR shape: (236,)\n",
      "Index 760 - Left HRIR shape: (236,), Right HRIR shape: (236,)\n",
      "Index 12 - Left HRIR shape: (236,), Right HRIR shape: (236,)\n",
      "Index 369 - Left HRIR shape: (236,), Right HRIR shape: (236,)\n",
      "Index 5876 - Left HRIR shape: (236,), Right HRIR shape: (236,)\n",
      "Index 2950 - Left HRIR shape: (236,), Right HRIR shape: (236,)\n"
     ]
    }
   ],
   "source": [
    "target_indices = [8064, 760, 12, 369, 5876, 2950]\n",
    "with h5py.File('/Users/vio/Downloads/D2_HRIR_SOFA/D2_48K_24bit_256tap_FIR_SOFA.sofa', 'r') as f:\n",
    "    hrir_data = f['Data.IR'][:]  # Get HRIR data\n",
    "    original_sample_rate = f['Data.SamplingRate'][0]  # Get the original sampling rate\n",
    "\n",
    "    # Prepare a dictionary to hold the resampled HRIRs\n",
    "    resampled_hrir_data = {}\n",
    "\n",
    "    # Process each target index\n",
    "    for index in target_indices:\n",
    "        # Load HRIRs for the specified index (ensure you understand the data shape and channel layout)\n",
    "        hrir_left = hrir_data[index, 0, :]  # Assuming the first channel is left\n",
    "        hrir_right = hrir_data[index, 1, :]  # Assuming the second channel is right\n",
    "\n",
    "        # Resample HRIRs from original_sample_rate (48 kHz) to 44.1 kHz\n",
    "        hrir_left_resampled = librosa.resample(hrir_left, orig_sr=original_sample_rate, target_sr=44100)\n",
    "        hrir_right_resampled = librosa.resample(hrir_right, orig_sr=original_sample_rate, target_sr=44100)\n",
    "\n",
    "        # Store resampled HRIRs\n",
    "        resampled_hrir_data[index] = {\n",
    "            'left': hrir_left_resampled,\n",
    "            'right': hrir_right_resampled\n",
    "        }\n",
    "\n",
    "# Output the shapes of the resampled HRIRs to verify\n",
    "for index, hrirs in resampled_hrir_data.items():\n",
    "    print(f\"Index {index} - Left HRIR shape: {hrirs['left'].shape}, Right HRIR shape: {hrirs['right'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff2de41",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f262f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hrir(audio_np, hrir_left, hrir_right):\n",
    "    \"\"\"\n",
    "    Convolves stereo HRIR with a mono audio signal, returning stereo output.\n",
    "    \"\"\"\n",
    "    left = np.convolve(audio_np, hrir_left, mode='full')[:len(audio_np)]\n",
    "    right = np.convolve(audio_np, hrir_right, mode='full')[:len(audio_np)]\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d606075",
   "metadata": {},
   "outputs": [],
   "source": [
    "front_left_stereo = apply_hrir(front_left_np, resampled_hrir_data[8064]['left'], resampled_hrir_data[8064]['right'])\n",
    "front_right_stereo = apply_hrir(front_right_np, resampled_hrir_data[760]['left'], resampled_hrir_data[760]['right'])\n",
    "center_stereo = apply_hrir(center_np, resampled_hrir_data[12]['left'], resampled_hrir_data[12]['right'])\n",
    "lfe_stereo = apply_hrir(lfe_np, resampled_hrir_data[369]['left'], resampled_hrir_data[369]['right']) \n",
    "surround_left_stereo = apply_hrir(surround_left_np, resampled_hrir_data[5876]['left'], resampled_hrir_data[5876]['right'])\n",
    "surround_right_stereo = apply_hrir(surround_right_np, resampled_hrir_data[2950]['left'], resampled_hrir_data[2950]['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45e7e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_left = front_left_stereo[0] + front_right_stereo[0] + center_stereo[0] + lfe_stereo[0] + surround_left_stereo[0] + surround_right_stereo[0]\n",
    "final_right = front_left_stereo[1] + front_right_stereo[1] + center_stereo[1] + lfe_stereo[1] + surround_left_stereo[1] + surround_right_stereo[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dab1afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_stereo(final_left, final_right):\n",
    "\n",
    "    peak_amplitude = np.max(np.abs([final_left, final_right]))\n",
    "    normalization_factor = 1.0 / peak_amplitude\n",
    "\n",
    "    # Normalize both channels\n",
    "    normalized_left = final_left * normalization_factor\n",
    "    normalized_right = final_right * normalization_factor\n",
    "\n",
    "    return normalized_left, normalized_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd433665",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_left, normalized_right = normalize_stereo(final_left, final_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e29acc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vss = np.vstack((normalized_left, normalized_right)).T\n",
    "sf.write('final_vss_mix.wav', final_vss, 44100, 'PCM_24')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e178081a",
   "metadata": {},
   "source": [
    "### The result is nice, but I want to make sure the LUFS stays consistent \n",
    "#### Actually forget about this part cuz I found that after loudness adjustment, the VSS auditory experience doesn't feel right."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba68f636",
   "metadata": {},
   "source": [
    "#### I use my DAW to calculate the LUFS of my original 5.1 audio -> -13.4 LUFS"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e215ee43",
   "metadata": {},
   "source": [
    "def adjust_loudness(audio_data, samplerate, target_loudness):\n",
    "    meter = pyln.Meter(samplerate)  # create BS.1770 meter\n",
    "    loudness = meter.integrated_loudness(audio_data)\n",
    "    # Calculate the required gain\n",
    "    gain = 10**((target_loudness - loudness) / 20)\n",
    "    # Apply gain\n",
    "    adjusted_audio = audio_data * gain\n",
    "    return adjusted_audio"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94026a29",
   "metadata": {},
   "source": [
    "# Load, measure, and adjust stereo downmixed and VSS-processed audio\n",
    "stereo_data, sr = sf.read(\"stereo_downmix.wav\")\n",
    "vss_data, sr = sf.read(\"final_vss_mix.wav\")\n",
    "\n",
    "target_loudness = -13.4\n",
    "adjusted_stereo = adjust_loudness(stereo_data, sr, target_loudness)\n",
    "adjusted_vss = adjust_loudness(vss_data, sr, target_loudness)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8381940c",
   "metadata": {},
   "source": [
    "sf.write('adjusted_stereo_downmix.wav', adjusted_stereo, sr)\n",
    "sf.write('adjusted_final_vss_mix.wav', adjusted_vss, sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VSS",
   "language": "python",
   "name": "vss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
